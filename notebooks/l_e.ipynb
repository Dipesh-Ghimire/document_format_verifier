{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "pdf_path = \"../dataset/pdfs/toxicMeter.pdf\" \n",
    "doc = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body_font_type': 'TimesNewRomanPSMT', 'body_font_size': 12, 'heading_font_type': 'TimesNewRomanPS-BoldMT', 'heading_font_size': 18}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from collections import Counter\n",
    "\n",
    "def extract_font_details(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # Open the PDF\n",
    "    font_data = []  # Store all (font_name, font_size) occurrences\n",
    "\n",
    "    for page_num in range(1,len(doc)):\n",
    "        page = doc[page_num]\n",
    "        text_instances = page.get_text(\"dict\")[\"blocks\"]  # Extract text blocks\n",
    "\n",
    "        for block in text_instances:\n",
    "            if \"lines\" in block:  # Ensure block contains text\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:  # Spans contain font information\n",
    "                        font_name = span[\"font\"]\n",
    "                        font_size = round(span[\"size\"])  # Round font size for consistency\n",
    "                        font_data.append((font_name, font_size))\n",
    "\n",
    "    if not font_data:\n",
    "        return {\"error\": \"No font data found in the document.\"}\n",
    "\n",
    "    # Count occurrences of font sizes\n",
    "    font_size_counts = Counter(size for _, size in font_data)\n",
    "    \n",
    "    # Determine body font size (most frequent)\n",
    "    most_common_font_size, _ = font_size_counts.most_common(1)[0]  \n",
    "\n",
    "    # Determine heading font size\n",
    "    sorted_font_sizes = sorted(font_size_counts.items(), key=lambda x: x[0], reverse=True)  # Sort by size desc\n",
    "\n",
    "    heading_font_size = None\n",
    "    for i, (size, count) in enumerate(sorted_font_sizes):\n",
    "        if i == 0 and count < 5:  # Drop max size if occurrences < 5\n",
    "            continue\n",
    "        heading_font_size = size\n",
    "        break\n",
    "\n",
    "    if not heading_font_size:\n",
    "        heading_font_size = most_common_font_size  # Fallback to body size if no valid heading font\n",
    "\n",
    "    # Identify corresponding font names\n",
    "    body_font = next((font for font, size in font_data if size == most_common_font_size), \"Unknown\")\n",
    "    heading_font = next((font for font, size in font_data if size == heading_font_size), \"Unknown\")\n",
    "\n",
    "    # Return extracted font details\n",
    "    return {\n",
    "        \"body_font_type\": body_font,\n",
    "        \"body_font_size\": most_common_font_size,\n",
    "        \"heading_font_type\": heading_font,\n",
    "        \"heading_font_size\": heading_font_size\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    " # Replace with the actual PDF path\n",
    "font_details = extract_font_details(pdf_path)\n",
    "print(font_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table_of_contents': {'toc_present': True, 'heading_font_size': 16, 'subheading_font_size': 14}}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_toc_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])  # Extract all text\n",
    "    \n",
    "    # Check for Table of Contents presence\n",
    "    toc_present = \"Table of Contents\" in text or \"TABLE OF CONTENTS\" in text\n",
    "\n",
    "    # Extract fonts from the first few pages\n",
    "    font_sizes = []\n",
    "    for page in doc[:5]:  # Check first 5 pages for heading fonts\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line[\"spans\"]:\n",
    "                    font_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    # Determine heading and subheading font sizes\n",
    "    if font_sizes:\n",
    "        heading_font_size = max(font_sizes)  # Largest font used\n",
    "        subheading_font_size = sorted(set(font_sizes), reverse=True)[1] if len(set(font_sizes)) > 1 else heading_font_size\n",
    "    else:\n",
    "        heading_font_size = subheading_font_size = None\n",
    "\n",
    "    return {\n",
    "        \"table_of_contents\": {\n",
    "            \"toc_present\": toc_present,\n",
    "            \"heading_font_size\": heading_font_size,\n",
    "            \"subheading_font_size\": subheading_font_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "toc_info = extract_toc_info(\"toxicMeter.pdf\")\n",
    "print(toc_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'list_of_figures': {'lof_present': True, 'figure_caption_font_size': 12}}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def extract_lof_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])\n",
    "    \n",
    "    # Check for List of Figures presence\n",
    "    lof_present = \"List of Figures\" in text or \"LIST OF FIGURES\" in text\n",
    "\n",
    "    # Extract font size of figure captions (Search for 'Figure' keyword)\n",
    "    caption_sizes = []\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line[\"spans\"]:\n",
    "                    if \"Figure\" in span[\"text\"]:  # Detect captions\n",
    "                        caption_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    #Find the most frequent figure caption font size\n",
    "    font_counts = Counter(caption_sizes)\n",
    "    figure_caption_font_size = font_counts.most_common(1)[0][0] if font_counts else None\n",
    "\n",
    "    return {\n",
    "        \"list_of_figures\": {\n",
    "            \"lof_present\": lof_present,\n",
    "            \"figure_caption_font_size\": figure_caption_font_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "lof_info = extract_lof_info(\"toxicMeter.pdf\")\n",
    "print(lof_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abbreviations_section': {'abbreviations_section_present': False, 'abbreviations_sorted': 'N/A', 'abbreviations': {}}}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_abbreviations_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_page = None\n",
    "    heading_font_size = None\n",
    "    abbreviations_dict = {}\n",
    "\n",
    "    # Step 1: Identify general heading font size from the first few pages\n",
    "    font_sizes = []\n",
    "    for page in doc[:5]:  # Check first 5 pages to identify common heading font\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue  # Skip blocks without text lines\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    font_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    # Determine most common heading font size\n",
    "    general_heading_font_size = max(font_sizes) if font_sizes else None\n",
    "\n",
    "    if general_heading_font_size is None:\n",
    "        return {\n",
    "            \"abbreviations_section\": {\n",
    "                \"abbreviations_section_present\": False,\n",
    "                \"abbreviations_sorted\": \"N/A\",\n",
    "                \"abbreviations\": {}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Step 2: Locate \"List of Abbreviations\" with the matched heading font size\n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    if span[\"size\"] == general_heading_font_size and (\n",
    "                        \"List of Abbreviations\" in span[\"text\"] or \"ABBREVIATIONS\" in span[\"text\"]\n",
    "                    ):\n",
    "                        abbreviations_page = page_num\n",
    "                        break\n",
    "            if abbreviations_page is not None:\n",
    "                break\n",
    "        if abbreviations_page is not None:\n",
    "            break\n",
    "\n",
    "    if abbreviations_page is None:\n",
    "        return {\n",
    "            \"abbreviations_section\": {\n",
    "                \"abbreviations_section_present\": False,\n",
    "                \"abbreviations_sorted\": \"N/A\",\n",
    "                \"abbreviations\": {}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Step 3: Extract abbreviations from the identified page\n",
    "    text = doc[abbreviations_page].get_text(\"dict\")\n",
    "    capture_abbreviations = False  # Start capturing only after heading\n",
    "\n",
    "    abbreviation_pattern = re.compile(r\"^([A-Z0-9\\-]+)[:\\s]+(.+)\")  # Match \"ABC: Definition\"\n",
    "\n",
    "    for block in text[\"blocks\"]:\n",
    "        if \"lines\" not in block:\n",
    "            continue  # Skip empty blocks\n",
    "        for line in block[\"lines\"]:\n",
    "            for span in line[\"spans\"]:\n",
    "                font_size = span[\"size\"]\n",
    "                content = span[\"text\"].strip()\n",
    "\n",
    "                # Step 4: Detect start of abbreviations section\n",
    "                if font_size == general_heading_font_size and (\"List of Abbreviations\" in content or \"ABBREVIATIONS\" in content):\n",
    "                    capture_abbreviations = True\n",
    "                    continue\n",
    "\n",
    "                # Step 5: Capture abbreviations only after the heading\n",
    "                if capture_abbreviations:\n",
    "                    match = abbreviation_pattern.match(content)\n",
    "                    if match:\n",
    "                        abbrev, definition = match.groups()\n",
    "                        abbreviations_dict[abbrev] = definition\n",
    "\n",
    "    # Step 6: Check if abbreviations are sorted\n",
    "    sorted_status = \"asc\" if list(abbreviations_dict.keys()) == sorted(abbreviations_dict.keys()) else \"unsorted\"\n",
    "\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": True,\n",
    "            \"abbreviations_sorted\": sorted_status,\n",
    "            \"abbreviations\": abbreviations_dict\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run the function\n",
    "abbr_info = extract_abbreviations_info(\"toxicMeter.pdf\")\n",
    "print(abbr_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "pdf_path = \"../dataset/pdfs/toxicMeter.pdf\" \n",
    "doc = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Content Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_of_contents\": {\n",
      "    \"toc_present\": true,\n",
      "    \"heading_font_size\": 16,\n",
      "    \"subheading_font_size\": 12\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def table_of_content_extractor(doc):\n",
    "    toc_text = \"\"\n",
    "    toc_found = False  # Flag to track if ToC has started\n",
    "    potential_toc = []  # Store potential ToC lines\n",
    "    toc_fonts = []  # Store font size information\n",
    "    toc_heading_size = None  # Track ToC heading font size (only once)\n",
    "    subheading_sizes = set()  # Track unique subheading font sizes\n",
    "\n",
    "    # Iterate through first few pages (ToC is usually at the beginning)\n",
    "    for page_num in range(min(10, len(doc))):  # Scan first 10 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect ToC heading (ensure we only capture the first occurrence)\n",
    "                        if re.search(r\"\\b(Table\\s*of\\s*Contents|Contents|Index)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not toc_found:  # Only set once\n",
    "                                toc_found = True  \n",
    "                                toc_heading_size = font_size  # Store only the first ToC heading font size\n",
    "                                toc_fonts.append((\"Heading\", line_text, font_size))\n",
    "                            toc_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If ToC has started, keep extracting until a matching font size is detected\n",
    "                        if toc_found:\n",
    "                            # Stop when encountering a section heading of the same size as the ToC heading\n",
    "                            if font_size == toc_heading_size:\n",
    "                                return {\n",
    "                                    \"table_of_contents\": {\n",
    "                                        \"toc_present\": True,\n",
    "                                        \"heading_font_size\": toc_heading_size,\n",
    "                                        \"subheading_font_size\": max(subheading_sizes) if subheading_sizes else None\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            # Identify ToC subheadings based on detected text patterns\n",
    "                            if re.match(r\"^\\d+(\\.\\d+)*\\s+[A-Za-z\\s]+\", line_text):  \n",
    "                                subheading_sizes.add(font_size)  # Store unique subheading font sizes\n",
    "                                toc_fonts.append((\"Subheading\", line_text, font_size))\n",
    "                            else:\n",
    "                                toc_fonts.append((\"Regular\", line_text, font_size))\n",
    "\n",
    "                            potential_toc.append(line_text)\n",
    "                            toc_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no ToC found, return False\n",
    "    return {\n",
    "        \"table_of_contents\": {\n",
    "            \"toc_present\": False,\n",
    "            \"heading_font_size\": None,\n",
    "            \"subheading_font_size\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "toc_data = table_of_content_extractor(doc)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(toc_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Figure Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"list_of_figures\": {\n",
      "    \"lof_present\": true,\n",
      "    \"figure_caption_font_size\": 12\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def list_of_figures_extractor(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    lof_text = \"\"\n",
    "    lof_found = False  # Flag to track if LoF has started\n",
    "    figure_caption_sizes = set()  # Store unique font sizes of figure captions\n",
    "    lof_heading_size = None  # Track LoF heading font size\n",
    "\n",
    "    # Iterate through first few pages (LoF is usually at the beginning)\n",
    "    for page_num in range(min(10, len(doc))):  # Scan first 10 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect LoF heading (ensuring we only capture the first occurrence)\n",
    "                        if re.search(r\"\\b(List\\s*of\\s*Figures|Figures|Figure Index)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not lof_found:  # Only set once\n",
    "                                lof_found = True  \n",
    "                                lof_heading_size = font_size  # Store LoF heading font size\n",
    "                            lof_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If LoF has started, keep extracting until a matching font size is detected\n",
    "                        if lof_found:\n",
    "                            # Identify figure captions (likely smaller font size than heading)\n",
    "                            if re.match(r\"^(Figure|Fig\\.|Table)\\s+\\d+[:.\\s]\", line_text):  \n",
    "                                figure_caption_sizes.add(font_size)  # Store caption font size\n",
    "\n",
    "                            # Stop when encountering a section heading of the same size as the LoF heading,\n",
    "                            # BUT only if we have already captured some figure captions.\n",
    "                            if font_size == lof_heading_size and figure_caption_sizes:\n",
    "                                return {\n",
    "                                    \"list_of_figures\": {\n",
    "                                        \"lof_present\": True,\n",
    "                                        \"figure_caption_font_size\": max(figure_caption_sizes)  # Return largest detected caption font\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            lof_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no LoF found, return False\n",
    "    return {\n",
    "        \"list_of_figures\": {\n",
    "            \"lof_present\": False,\n",
    "            \"figure_caption_font_size\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "lof_data = list_of_figures_extractor(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(lof_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviations Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"abbreviations_section\": {\n",
      "    \"abbreviations_section_present\": true,\n",
      "    \"abbreviations_sorted\": \"asc\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_abbreviations_section(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_text = \"\"\n",
    "    abbreviations_found = False  # Flag to track if abbreviations section has started\n",
    "    abbreviations = []  # Store extracted abbreviations\n",
    "    abbreviation_heading_size = None  # Store heading font size\n",
    "\n",
    "    # Iterate through first few pages (Abbreviations is usually at the beginning or middle)\n",
    "    for page_num in range(min(15, len(doc))):  # Scan first 15 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect Abbreviations heading\n",
    "                        if re.search(r\"\\b(Abbreviations|List of Abbreviations|Acronyms)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not abbreviations_found:  # Capture only the first heading\n",
    "                                abbreviations_found = True  \n",
    "                                abbreviation_heading_size = font_size  # Store the font size of this section\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If Abbreviations section has started, keep extracting until a new section heading is found\n",
    "                        if abbreviations_found:\n",
    "                            # Stop when encountering a section heading of the same size as the Abbreviations heading\n",
    "                            if font_size == abbreviation_heading_size:\n",
    "                                return {\n",
    "                                    \"abbreviations_section\": {\n",
    "                                        \"abbreviations_section_present\": True,\n",
    "                                        \"abbreviations_sorted\": check_sorting_order(abbreviations)  # Determine sorting order\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            # Alternative method to extract abbreviations\n",
    "                            extracted_abbreviation = extract_abbreviation_from_line(line_text)\n",
    "                            print(extracted_abbreviation)\n",
    "                            if extracted_abbreviation:\n",
    "                                abbreviations.append(extracted_abbreviation)\n",
    "\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no abbreviations section found, return False\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": False,\n",
    "            \"abbreviations_sorted\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_abbreviation_from_line(line_text):\n",
    "    \"\"\"\n",
    "    Extract abbreviations using different patterns:\n",
    "    1. AI (Artificial Intelligence)\n",
    "    2. CNN: Convolutional Neural Network\n",
    "    3. NLP – Natural Language Processing\n",
    "    \"\"\"\n",
    "    print(line_text)\n",
    "    # Look for patterns like \"AI (Artificial Intelligence)\"\n",
    "    match_parentheses = re.match(r\"^([A-Z]{2,})\\s*\\((.+?)\\)$\", line_text)\n",
    "    if match_parentheses:\n",
    "        return match_parentheses.group(1)  # Extract \"AI\"\n",
    "\n",
    "    # Look for patterns like \"CNN: Convolutional Neural Network\"\n",
    "    match_colon = re.match(r\"^([A-Z]{2,})\\s*:\\s*(.+)$\", line_text)\n",
    "    if match_colon:\n",
    "        return match_colon.group(1)  # Extract \"CNN\"\n",
    "\n",
    "    # Look for patterns like \"NLP – Natural Language Processing\"\n",
    "    match_dash = re.match(r\"^([A-Z]{2,})\\s*[-–—]\\s*(.+)$\", line_text)\n",
    "    if match_dash:\n",
    "        return match_dash.group(1)  # Extract \"NLP\"\n",
    "\n",
    "    return None  # No match found\n",
    "\n",
    "def check_sorting_order(abbreviations):\n",
    "    \"\"\"Determine if abbreviations are sorted in ascending, descending, or no order.\"\"\"\n",
    "    if abbreviations == sorted(abbreviations):\n",
    "        return \"asc\"\n",
    "    elif abbreviations == sorted(abbreviations, reverse=True):\n",
    "        return \"desc\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "\n",
    "abbreviations_data = extract_abbreviations_section(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(abbreviations_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"abbreviations_section\": {\n",
      "    \"abbreviations_section_present\": false,\n",
      "    \"abbreviations_sorted\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_abbreviations_section(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_text = \"\"\n",
    "    abbreviations_found = False  # Flag to track if abbreviations section has started\n",
    "    abbreviations = []  # Store extracted abbreviations\n",
    "\n",
    "    # Iterate through the first few pages (Abbreviations section is usually in the early pages)\n",
    "    for page_num in range(min(15, len(doc))):  # Scan first 15 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect Abbreviations heading\n",
    "                        if re.search(r\"\\b(Abbreviations|List of Abbreviations|Acronyms)\\b\", line_text, re.IGNORECASE):\n",
    "                            abbreviations_found = True  # Start collecting abbreviations\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If Abbreviations section has started, extract abbreviations\n",
    "                        if abbreviations_found:\n",
    "                            extracted_abbreviation = extract_abbreviation_from_line(line_text)\n",
    "                            if extracted_abbreviation:\n",
    "                                abbreviations.append(extracted_abbreviation)\n",
    "\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "\n",
    "                            # Detect potential new section heading (Stop extraction here)\n",
    "                            if is_new_section_heading(line_text):\n",
    "                                return {\n",
    "                                    \"abbreviations_section\": {\n",
    "                                        \"abbreviations_section_present\": True,\n",
    "                                        \"abbreviations_sorted\": check_sorting_order(abbreviations)  # Determine sorting order\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "    # If no abbreviations section found, return False\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": False,\n",
    "            \"abbreviations_sorted\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_abbreviation_from_line(line_text):\n",
    "    \"\"\"\n",
    "    Extract abbreviations from a line by detecting:\n",
    "    1. AI - Artificial Intelligence\n",
    "    2. CNN : Convolutional Neural Network\n",
    "    3. NLP – Natural Language Processing\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-Z0-9]{2,})\\s*[-–—:]\\s*(.+)$\", line_text)\n",
    "    if match:\n",
    "        return match.group(1)  # Extract only the short form (e.g., AI, CNN, NLP)\n",
    "\n",
    "    return None  # No abbreviation found\n",
    "\n",
    "def is_new_section_heading(line_text):\n",
    "    \"\"\"\n",
    "    Detect if a line is likely a new section heading:\n",
    "    - Fully capitalized words (e.g., \"INTRODUCTION\", \"METHODS\")\n",
    "    - Very short headings (1-3 words)\n",
    "    \"\"\"\n",
    "    if line_text.isupper() and len(line_text.split()) <= 5:\n",
    "        return True  # Likely a new section heading\n",
    "\n",
    "    return False  # Continue extracting abbreviations\n",
    "\n",
    "def check_sorting_order(abbreviations):\n",
    "    \"\"\"Determine if abbreviations are sorted in ascending, descending, or no order.\"\"\"\n",
    "    if abbreviations == sorted(abbreviations):\n",
    "        return \"asc\"\n",
    "    elif abbreviations == sorted(abbreviations, reverse=True):\n",
    "        return \"desc\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "# Example usage\n",
    "abbreviations_data = extract_abbreviations_section(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(abbreviations_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIGURE PLACEMENT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"figure_placement\": {\n",
      "    \"figure_caption_font_size\": 12,\n",
      "    \"figure_placement\": \"center\",\n",
      "    \"figure_caption_position\": \"above\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def figure_data_extractor(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_width = doc[0].rect.width  # Get the width of the first page for alignment checks\n",
    "\n",
    "    figure_placements = []  # Store placement data\n",
    "    caption_positions = []  # Store caption positions\n",
    "    caption_font_sizes = []  # Store caption font sizes\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        images = page.get_images(full=True)  # Extract all images (figures)\n",
    "\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]  # Get image reference\n",
    "            bbox = page.get_image_rects(xref)[0]  # Get bounding box of image (figure)\n",
    "\n",
    "            # Determine figure alignment\n",
    "            fig_x0, fig_y0, fig_x1, fig_y1 = bbox\n",
    "            fig_width = fig_x1 - fig_x0\n",
    "            page_center_x = page_width / 2\n",
    "\n",
    "            if abs((fig_x0 + fig_x1) / 2 - page_center_x) < fig_width * 0.1:\n",
    "                placement = \"center\"\n",
    "            elif fig_x0 < page_width * 0.3:\n",
    "                placement = \"left\"\n",
    "            else:\n",
    "                placement = \"right\"\n",
    "\n",
    "            # Find figure caption (text near the figure)\n",
    "            figure_caption, caption_font_size, caption_position = find_figure_caption(page, bbox)\n",
    "\n",
    "            if caption_font_size:\n",
    "                caption_font_sizes.append(caption_font_size)\n",
    "\n",
    "            if placement:\n",
    "                figure_placements.append(placement)\n",
    "\n",
    "            if caption_position:\n",
    "                caption_positions.append(caption_position)\n",
    "\n",
    "    # Determine most frequent values\n",
    "    most_common_placement = most_frequent(figure_placements)\n",
    "    most_common_caption_position = most_frequent(caption_positions)\n",
    "    most_common_caption_font_size = most_frequent(caption_font_sizes)\n",
    "\n",
    "    return {\n",
    "        \"figure_placement\": {\n",
    "            \"figure_caption_font_size\": most_common_caption_font_size,\n",
    "            \"figure_placement\": most_common_placement,\n",
    "            \"figure_caption_position\": most_common_caption_position\n",
    "        }\n",
    "    }\n",
    "\n",
    "def find_figure_caption(page, bbox):\n",
    "    \"\"\"\n",
    "    Find the caption text near the figure.\n",
    "    - If text appears *below* the figure, return \"below\"\n",
    "    - If text appears *above* the figure, return \"above\"\n",
    "    \"\"\"\n",
    "    fig_x0, fig_y0, fig_x1, fig_y1 = bbox\n",
    "    caption_text = None\n",
    "    caption_font_size = None\n",
    "    caption_position = None\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text_y0 = line[\"bbox\"][1]  # Get Y-position of text\n",
    "                    font_size = round(span[\"size\"])  # Extract font size\n",
    "                    line_text = span[\"text\"].strip()\n",
    "\n",
    "                    # Check if text is directly below the figure\n",
    "                    if fig_y1 < text_y0 < fig_y1 + font_size * 3:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"below\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "                    # Check if text is directly above the figure\n",
    "                    if fig_y0 - font_size * 3 < text_y0 < fig_y0:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"above\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "    return caption_text, caption_font_size, caption_position\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "figure_placement_data = figure_data_extractor(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(figure_placement_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TABLE PLACEMENT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_placement\": {\n",
      "    \"table_caption_font_size\": 12,\n",
      "    \"table_placement\": \"right\",\n",
      "    \"table_caption_position\": \"above\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_table_placement(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_width = doc[0].rect.width  # Get the width of the first page for alignment checks\n",
    "\n",
    "    table_placements = []  # Store table alignment\n",
    "    caption_positions = []  # Store caption positions\n",
    "    caption_font_sizes = []  # Store caption font sizes\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        tables = find_tables(page)  # Find potential table bounding boxes\n",
    "\n",
    "        for table_bbox in tables:\n",
    "            # Determine table alignment\n",
    "            table_x0, table_y0, table_x1, table_y1 = table_bbox\n",
    "            table_width = table_x1 - table_x0\n",
    "            page_center_x = page_width / 2\n",
    "\n",
    "            if abs((table_x0 + table_x1) / 2 - page_center_x) < table_width * 0.1:\n",
    "                placement = \"center\"\n",
    "            elif table_x0 < page_width * 0.3:\n",
    "                placement = \"left\"\n",
    "            else:\n",
    "                placement = \"right\"\n",
    "\n",
    "            # Find table caption (text near the table)\n",
    "            table_caption, caption_font_size, caption_position = find_table_caption(page, table_bbox)\n",
    "\n",
    "            if caption_font_size:\n",
    "                caption_font_sizes.append(caption_font_size)\n",
    "\n",
    "            if placement:\n",
    "                table_placements.append(placement)\n",
    "\n",
    "            if caption_position:\n",
    "                caption_positions.append(caption_position)\n",
    "\n",
    "    # Determine most frequent values\n",
    "    most_common_placement = most_frequent(table_placements)\n",
    "    most_common_caption_position = most_frequent(caption_positions)\n",
    "    most_common_caption_font_size = most_frequent(caption_font_sizes)\n",
    "\n",
    "    return {\n",
    "        \"table_placement\": {\n",
    "            \"table_caption_font_size\": most_common_caption_font_size,\n",
    "            \"table_placement\": most_common_placement,\n",
    "            \"table_caption_position\": most_common_caption_position\n",
    "        }\n",
    "    }\n",
    "\n",
    "def find_tables(page):\n",
    "    \"\"\"\n",
    "    Identify potential tables by detecting large structured text blocks.\n",
    "    - Looks for multiple consecutive text lines forming a structured shape.\n",
    "    \"\"\"\n",
    "    table_bboxes = []\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block and len(block[\"lines\"]) > 2:  # More than 2 rows indicates a possible table\n",
    "            bbox = block[\"bbox\"]\n",
    "            table_bboxes.append(bbox)\n",
    "\n",
    "    return table_bboxes\n",
    "\n",
    "def find_table_caption(page, bbox):\n",
    "    \"\"\"\n",
    "    Find the caption text near the table.\n",
    "    - If text appears *below* the table, return \"below\"\n",
    "    - If text appears *above* the table, return \"above\"\n",
    "    \"\"\"\n",
    "    table_x0, table_y0, table_x1, table_y1 = bbox\n",
    "    caption_text = None\n",
    "    caption_font_size = None\n",
    "    caption_position = None\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text_y0 = line[\"bbox\"][1]  # Get Y-position of text\n",
    "                    font_size = round(span[\"size\"])  # Extract font size\n",
    "                    line_text = span[\"text\"].strip()\n",
    "\n",
    "                    # Check if text is directly below the table\n",
    "                    if table_y1 < text_y0 < table_y1 + font_size * 3:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"below\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "                    # Check if text is directly above the table\n",
    "                    if table_y0 - font_size * 3 < text_y0 < table_y0:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"above\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "    return caption_text, caption_font_size, caption_position\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "table_placement_data = extract_table_placement(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(table_placement_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT ALIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text_alignment\": {\n",
      "    \"text_alignment\": \"Justified\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_text_alignment(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    alignment_counts = []  # Store detected alignments\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                left_margins = []\n",
    "                right_margins = []\n",
    "\n",
    "                for line in block[\"lines\"]:\n",
    "                    x0, _, x1, _ = line[\"bbox\"]  # Get left & right positions of the line\n",
    "                    left_margins.append(x0)\n",
    "                    right_margins.append(x1)\n",
    "\n",
    "                # Compute alignment by analyzing variation in margins\n",
    "                left_variation = max(left_margins) - min(left_margins) if left_margins else 0\n",
    "                right_variation = max(right_margins) - min(right_margins) if right_margins else 0\n",
    "\n",
    "                if left_variation < 5 and right_variation < 5:\n",
    "                    alignment_counts.append(\"Justified\")\n",
    "                elif left_variation < 5:\n",
    "                    alignment_counts.append(\"Left\")\n",
    "                elif right_variation < 5:\n",
    "                    alignment_counts.append(\"Right\")\n",
    "                else:\n",
    "                    alignment_counts.append(\"Mixed\")\n",
    "\n",
    "    # Determine most frequent text alignment\n",
    "    most_common_alignment = most_frequent(alignment_counts)\n",
    "\n",
    "    return {\n",
    "        \"text_alignment\": {\n",
    "            \"text_alignment\": most_common_alignment\n",
    "        }\n",
    "    }\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "text_alignment_data = extract_text_alignment(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(text_alignment_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARGIN EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"margins\": {\n",
      "    \"left_margin_inch\": 1,\n",
      "    \"right_margin_inch\": 1,\n",
      "    \"top_margin_inch\": 2,\n",
      "    \"bottom_margin_inch\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "def extract_margins(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    margin_values = {\"left\": [], \"right\": [], \"top\": [], \"bottom\": []}\n",
    "\n",
    "    for page in doc:\n",
    "        page_width, page_height = page.rect.width, page.rect.height  # Page size in points\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        # Initialize extreme values for text placement\n",
    "        leftmost = page_width\n",
    "        rightmost = 0\n",
    "        topmost = page_height\n",
    "        bottommost = 0\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    x0, y0, x1, y1 = line[\"bbox\"]  # Bounding box (left, top, right, bottom)\n",
    "                    leftmost = min(leftmost, x0)\n",
    "                    rightmost = max(rightmost, x1)\n",
    "                    topmost = min(topmost, y0)\n",
    "                    bottommost = max(bottommost, y1)\n",
    "\n",
    "        # Calculate margins in inches (1 inch = 72 points)\n",
    "        left_margin = round(leftmost / 72, 2)\n",
    "        right_margin = round((page_width - rightmost) / 72, 2)\n",
    "        top_margin = round(topmost / 72, 2)\n",
    "        bottom_margin = round((page_height - bottommost) / 72, 2)\n",
    "\n",
    "        margin_values[\"left\"].append(left_margin)\n",
    "        margin_values[\"right\"].append(right_margin)\n",
    "        margin_values[\"top\"].append(top_margin)\n",
    "        margin_values[\"bottom\"].append(bottom_margin)\n",
    "\n",
    "    # Compute average margins across pages\n",
    "    avg_left_margin = round(sum(margin_values[\"left\"]) / len(margin_values[\"left\"]), 2)\n",
    "    avg_right_margin = round(sum(margin_values[\"right\"]) / len(margin_values[\"right\"]), 2)\n",
    "    avg_top_margin = round(sum(margin_values[\"top\"]) / len(margin_values[\"top\"]), 2)\n",
    "    avg_bottom_margin = round(sum(margin_values[\"bottom\"]) / len(margin_values[\"bottom\"]), 2)\n",
    "\n",
    "    return {\n",
    "        \"margins\": {\n",
    "            \"left_margin_inch\": round(avg_left_margin),\n",
    "            \"right_margin_inch\": round(avg_right_margin),\n",
    "            \"top_margin_inch\": round(avg_top_margin),\n",
    "            \"bottom_margin_inch\": round(avg_bottom_margin)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "margins_data = extract_margins(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(margins_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FONT EXTRACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"font_type_size\": {\n",
      "    \"body_font_type\": \"TimesNewRomanPSMT\",\n",
      "    \"body_font_size\": 12,\n",
      "    \"heading_font_type\": \"TimesNewRomanPS-BoldMT\",\n",
      "    \"heading_font_size\": 18\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_font_data(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    # skip first page from doc\n",
    "    doc = doc[1:]\n",
    "    font_sizes = []\n",
    "    font_types = []\n",
    "    heading_fonts = []\n",
    "    \n",
    "    for page in doc:\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        font_type = span[\"font\"]  # Extract font type\n",
    "                        font_sizes.append(font_size)\n",
    "                        font_types.append(font_type)\n",
    "\n",
    "    # Identify the most common font type & size for body text\n",
    "    most_common_body_font = most_frequent(font_types)\n",
    "    most_common_body_size = most_frequent(font_sizes)\n",
    "\n",
    "    # Identify the most common font & size for headings (largest text)\n",
    "    max_font_size = max(font_sizes) if font_sizes else None\n",
    "    heading_fonts = [font for font, size in zip(font_types, font_sizes) if size == max_font_size]\n",
    "    most_common_heading_font = most_frequent(heading_fonts)\n",
    "\n",
    "    return {\n",
    "        \"font_type_size\": {\n",
    "            \"body_font_type\": most_common_body_font,\n",
    "            \"body_font_size\": most_common_body_size,\n",
    "            \"heading_font_type\": most_common_heading_font,\n",
    "            \"heading_font_size\": max_font_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "font_data = extract_font_data(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(font_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFERENCE FORMATTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"references_formatting\": {\n",
      "    \"references_format\": null,\n",
      "    \"citations_consistent\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_references_formatting(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    references_text = \"\"\n",
    "    references_found = False  # Track if References section is found\n",
    "    references_list = []  # Store extracted references\n",
    "    reference_format = None\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through pages\n",
    "        text_blocks = doc[page_num].get_text(\"text\").split(\"\\n\")  # Extract text line by line\n",
    "\n",
    "        for line in text_blocks:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Detect References section heading\n",
    "            if re.search(r\"\\b(References|Bibliography|Works Cited)\\b\", line, re.IGNORECASE):\n",
    "                references_found = True\n",
    "                continue  # Move to the next line\n",
    "\n",
    "            # If References section is found, collect reference entries\n",
    "            if references_found:\n",
    "                if re.match(r\"^\\[?\\d+\\]?\", line) or re.search(r\"\\(\\d{4}\\)\", line) or re.match(r\"^\\w+\\.\", line):\n",
    "                    references_list.append(line)\n",
    "\n",
    "            # Stop extraction when encountering a new section (empty line or unrelated text)\n",
    "            if references_found and line == \"\":\n",
    "                break\n",
    "\n",
    "    # Determine reference format\n",
    "    reference_format = detect_reference_format(references_list)\n",
    "\n",
    "    # Check citation consistency\n",
    "    consistent_format = len(set(reference_format)) == 1 if reference_format else False\n",
    "\n",
    "    return {\n",
    "        \"references_formatting\": {\n",
    "            \"references_format\": reference_format[0] if reference_format else None,\n",
    "            \"citations_consistent\": consistent_format\n",
    "        }\n",
    "    }\n",
    "\n",
    "def detect_reference_format(references):\n",
    "    \"\"\"\n",
    "    Detect the reference format: IEEE, APA, or MLA.\n",
    "    \"\"\"\n",
    "    formats_detected = []\n",
    "\n",
    "    for ref in references:\n",
    "        if re.match(r\"^\\[\\d+\\]\", ref):  # IEEE format (numbered)\n",
    "            formats_detected.append(\"IEEE\")\n",
    "        elif re.search(r\"\\(\\d{4}\\)\", ref):  # APA format (year in parentheses)\n",
    "            formats_detected.append(\"APA\")\n",
    "        elif re.match(r\"^\\w+\\.\", ref) and not re.search(r\"\\(\\d{4}\\)\", ref):  # MLA format (author + title)\n",
    "            formats_detected.append(\"MLA\")\n",
    "\n",
    "    return list(set(formats_detected))  # Return unique formats detected\n",
    "\n",
    "# Example usage\n",
    "references_data = extract_references_formatting(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(references_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"references_formatting\": {\n",
      "    \"references_format\": \"Unknown\",\n",
      "    \"citations_consistent\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_references_format(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    references_found = False\n",
    "    references_text = []\n",
    "    \n",
    "    # Scan pages to find the References section\n",
    "    for page in doc:\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    line_text = line[\"spans\"][0][\"text\"].strip()\n",
    "\n",
    "                    # Detect References section\n",
    "                    if re.search(r\"\\b(References|Bibliography|Citations)\\b\", line_text, re.IGNORECASE):\n",
    "                        references_found = True\n",
    "                        continue  # Move to extracting references\n",
    "\n",
    "                    # Extract reference lines until a new section starts\n",
    "                    if references_found:\n",
    "                        if is_new_section_heading(line_text):\n",
    "                            break\n",
    "                        references_text.append(line_text)\n",
    "\n",
    "    # Classify Reference Format\n",
    "    reference_format = classify_reference_format(references_text)\n",
    "    consistency = check_reference_consistency(references_text, reference_format)\n",
    "\n",
    "    return {\n",
    "        \"references_formatting\": {\n",
    "            \"references_format\": reference_format,\n",
    "            \"citations_consistent\": consistency\n",
    "        }\n",
    "    }\n",
    "\n",
    "def classify_reference_format(references):\n",
    "    \"\"\"\n",
    "    Classifies the reference format based on common citation styles:\n",
    "    - IEEE: [1] Author, \"Title,\" etc.\n",
    "    - APA: (Author, Year)\n",
    "    - MLA: Author. \"Title.\" etc.\n",
    "    \"\"\"\n",
    "    ieee_pattern = re.compile(r\"^\\[\\d+\\]\\s+.+\")\n",
    "    apa_pattern = re.compile(r\".+\\(\\d{4}\\)\\..+\")\n",
    "    mla_pattern = re.compile(r\"^[A-Z][a-z]+,\\s[A-Z][a-z]+\\..+\")\n",
    "\n",
    "    ieee_count = sum(1 for ref in references if ieee_pattern.match(ref))\n",
    "    apa_count = sum(1 for ref in references if apa_pattern.match(ref))\n",
    "    mla_count = sum(1 for ref in references if mla_pattern.match(ref))\n",
    "\n",
    "    # Determine dominant format\n",
    "    if ieee_count > apa_count and ieee_count > mla_count:\n",
    "        return \"IEEE\"\n",
    "    elif apa_count > ieee_count and apa_count > mla_count:\n",
    "        return \"APA\"\n",
    "    elif mla_count > ieee_count and mla_count > apa_count:\n",
    "        return \"MLA\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def check_reference_consistency(references, detected_format):\n",
    "    \"\"\"Checks if most references follow the detected citation format.\"\"\"\n",
    "    if detected_format == \"Unknown\":\n",
    "        return False\n",
    "    format_counts = Counter([classify_reference_format([ref]) for ref in references])\n",
    "    return format_counts[detected_format] / max(1, len(references)) > 0.8  # At least 80% must match\n",
    "\n",
    "def is_new_section_heading(line_text):\n",
    "    \"\"\"\n",
    "    Detects if a line is likely a new section heading:\n",
    "    - Fully capitalized words (e.g., \"INTRODUCTION\", \"CONCLUSION\")\n",
    "    - Short phrases (1-5 words)\n",
    "    \"\"\"\n",
    "    return line_text.isupper() and len(line_text.split()) <= 5\n",
    "\n",
    "\n",
    "references_data = extract_references_format(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(references_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"references_formatting\": {\n",
      "    \"references_format\": \"MLA\",\n",
      "    \"citations_consistent\": false\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_references_formatting(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    references_text = \"\"\n",
    "    references_found = False  # Track if References section is found\n",
    "    references_list = []  # Store extracted references\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through pages\n",
    "        text_blocks = doc[page_num].get_text(\"text\").split(\"\\n\")  # Extract text line by line\n",
    "\n",
    "        for line in text_blocks:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Detect References section heading\n",
    "            if re.search(r\"\\b(References|Bibliography|Works Cited)\\b\", line, re.IGNORECASE):\n",
    "                references_found = True\n",
    "                continue  # Move to the next line\n",
    "\n",
    "            # If References section is found, collect reference entries\n",
    "            if references_found:\n",
    "                if re.match(r\"^\\[\\d+\\]\", line) or re.search(r\"\\(\\d{4}\\)\", line) or re.match(r\"^\\w+\\.\", line):\n",
    "                    references_list.append(line)\n",
    "\n",
    "            # Stop extraction when encountering a new section heading (fully uppercase or unrelated keywords)\n",
    "            if references_found and re.match(r\"^[A-Z\\s]+$\", line) and len(line.split()) <= 5:\n",
    "                break\n",
    "\n",
    "    # Determine reference format\n",
    "    detected_formats = detect_reference_format(references_list)\n",
    "\n",
    "    # Check citation consistency\n",
    "    consistent_format = len(set(detected_formats)) == 1 if detected_formats else False\n",
    "\n",
    "    return {\n",
    "        \"references_formatting\": {\n",
    "            \"references_format\": detected_formats[0] if detected_formats else None,\n",
    "            \"citations_consistent\": consistent_format\n",
    "        }\n",
    "    }\n",
    "\n",
    "def detect_reference_format(references):\n",
    "    \"\"\"\n",
    "    Detect the reference format: IEEE, APA, or MLA.\n",
    "    \"\"\"\n",
    "    formats_detected = []\n",
    "\n",
    "    for ref in references:\n",
    "        if re.match(r\"^\\[\\d+\\]\", ref):  # IEEE format (numbered)\n",
    "            formats_detected.append(\"IEEE\")\n",
    "        elif re.search(r\"\\(\\d{4}\\)\", ref):  # APA format (year in parentheses)\n",
    "            formats_detected.append(\"APA\")\n",
    "        elif re.match(r\"^\\w+\\.\", ref) and not re.search(r\"\\(\\d{4}\\)\", ref):  # MLA format (author + title)\n",
    "            formats_detected.append(\"MLA\")\n",
    "\n",
    "    return list(set(formats_detected))  # Return unique formats detected\n",
    "\n",
    "# Example usage\n",
    "references_data = extract_references_formatting(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(references_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABBREVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'API', 'BERT', 'CNN', 'CSV', 'GPU', 'HTTP', 'JSON', 'LR', 'ML', 'MNB', 'NLP', 'NLTK', 'ORM', 'REST', 'ROC', 'TF']\n",
      "{\n",
      "  \"abbreviations_section\": {\n",
      "    \"abbreviations_section_present\": true,\n",
      "    \"abbreviations_sorted\": \"asc\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def abbreviations_extractor(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations = []  # Store extracted abbreviations\n",
    "    abbreviations_found = False  # Track if we are in the abbreviations list\n",
    "\n",
    "    for page_num in range(min(15, len(doc))):  # Scan first 15 pages\n",
    "        text_blocks = doc[page_num].get_text(\"text\").split(\"\\n\")  # Extract text line by line\n",
    "        lines = [line.strip() for line in text_blocks if line.strip()]  # Remove empty lines\n",
    "\n",
    "        for line in lines:\n",
    "            # Detect Abbreviations heading\n",
    "            if re.search(r\"\\b(Abbreviations|List of Abbreviations|Acronyms)\\b\", line, re.IGNORECASE):\n",
    "                abbreviations_found = True  # Start collecting abbreviations\n",
    "                continue  # Move to the next line\n",
    "\n",
    "            # If in abbreviations section, extract valid abbreviation-long form pairs\n",
    "            if abbreviations_found:\n",
    "                match = re.match(r\"^([A-Z0-9]{2,})\\s*[-–—:]\\s*(.+)$\", line)  # Abbreviation - Long form\n",
    "                if match:\n",
    "                    abbreviations.append(match.group(1))  # Store the abbreviation\n",
    "                else:\n",
    "                    # If a capitalized word appears without a valid format, stop extraction (end of section)\n",
    "                    if re.match(r\"^[A-Z\\s]+$\", line) and len(line.split()) <= 5:\n",
    "                        break\n",
    "\n",
    "    # Determine sorting order\n",
    "    abbreviations_sorted = check_sorting_order(abbreviations)\n",
    "    print(abbreviations)\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": True if abbreviations else False,\n",
    "            \"abbreviations_sorted\": abbreviations_sorted\n",
    "        }\n",
    "    }\n",
    "\n",
    "def check_sorting_order(abbreviations):\n",
    "    \"\"\"Determine if abbreviations are sorted in ascending, descending, or no order.\"\"\"\n",
    "    if abbreviations == sorted(abbreviations):\n",
    "        return \"asc\"\n",
    "    elif abbreviations == sorted(abbreviations, reverse=True):\n",
    "        return \"desc\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "# Example usage\n",
    "abbreviations_data = abbreviations_extractor(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(abbreviations_data, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
