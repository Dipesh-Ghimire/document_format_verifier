{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "pdf_path = \"../dataset/pdfs/toxicMeter.pdf\" \n",
    "doc = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body_font_type': 'TimesNewRomanPSMT', 'body_font_size': 12, 'heading_font_type': 'TimesNewRomanPS-BoldMT', 'heading_font_size': 18}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from collections import Counter\n",
    "\n",
    "def extract_font_details(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # Open the PDF\n",
    "    font_data = []  # Store all (font_name, font_size) occurrences\n",
    "\n",
    "    for page_num in range(1,len(doc)):\n",
    "        page = doc[page_num]\n",
    "        text_instances = page.get_text(\"dict\")[\"blocks\"]  # Extract text blocks\n",
    "\n",
    "        for block in text_instances:\n",
    "            if \"lines\" in block:  # Ensure block contains text\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:  # Spans contain font information\n",
    "                        font_name = span[\"font\"]\n",
    "                        font_size = round(span[\"size\"])  # Round font size for consistency\n",
    "                        font_data.append((font_name, font_size))\n",
    "\n",
    "    if not font_data:\n",
    "        return {\"error\": \"No font data found in the document.\"}\n",
    "\n",
    "    # Count occurrences of font sizes\n",
    "    font_size_counts = Counter(size for _, size in font_data)\n",
    "    \n",
    "    # Determine body font size (most frequent)\n",
    "    most_common_font_size, _ = font_size_counts.most_common(1)[0]  \n",
    "\n",
    "    # Determine heading font size\n",
    "    sorted_font_sizes = sorted(font_size_counts.items(), key=lambda x: x[0], reverse=True)  # Sort by size desc\n",
    "\n",
    "    heading_font_size = None\n",
    "    for i, (size, count) in enumerate(sorted_font_sizes):\n",
    "        if i == 0 and count < 5:  # Drop max size if occurrences < 5\n",
    "            continue\n",
    "        heading_font_size = size\n",
    "        break\n",
    "\n",
    "    if not heading_font_size:\n",
    "        heading_font_size = most_common_font_size  # Fallback to body size if no valid heading font\n",
    "\n",
    "    # Identify corresponding font names\n",
    "    body_font = next((font for font, size in font_data if size == most_common_font_size), \"Unknown\")\n",
    "    heading_font = next((font for font, size in font_data if size == heading_font_size), \"Unknown\")\n",
    "\n",
    "    # Return extracted font details\n",
    "    return {\n",
    "        \"body_font_type\": body_font,\n",
    "        \"body_font_size\": most_common_font_size,\n",
    "        \"heading_font_type\": heading_font,\n",
    "        \"heading_font_size\": heading_font_size\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    " # Replace with the actual PDF path\n",
    "font_details = extract_font_details(pdf_path)\n",
    "print(font_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'table_of_contents': {'toc_present': True, 'heading_font_size': 16, 'subheading_font_size': 14}}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_toc_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])  # Extract all text\n",
    "    \n",
    "    # Check for Table of Contents presence\n",
    "    toc_present = \"Table of Contents\" in text or \"TABLE OF CONTENTS\" in text\n",
    "\n",
    "    # Extract fonts from the first few pages\n",
    "    font_sizes = []\n",
    "    for page in doc[:5]:  # Check first 5 pages for heading fonts\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line[\"spans\"]:\n",
    "                    font_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    # Determine heading and subheading font sizes\n",
    "    if font_sizes:\n",
    "        heading_font_size = max(font_sizes)  # Largest font used\n",
    "        subheading_font_size = sorted(set(font_sizes), reverse=True)[1] if len(set(font_sizes)) > 1 else heading_font_size\n",
    "    else:\n",
    "        heading_font_size = subheading_font_size = None\n",
    "\n",
    "    return {\n",
    "        \"table_of_contents\": {\n",
    "            \"toc_present\": toc_present,\n",
    "            \"heading_font_size\": heading_font_size,\n",
    "            \"subheading_font_size\": subheading_font_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "toc_info = extract_toc_info(\"toxicMeter.pdf\")\n",
    "print(toc_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'list_of_figures': {'lof_present': True, 'figure_caption_font_size': 12}}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def extract_lof_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \" \".join([page.get_text(\"text\") for page in doc])\n",
    "    \n",
    "    # Check for List of Figures presence\n",
    "    lof_present = \"List of Figures\" in text or \"LIST OF FIGURES\" in text\n",
    "\n",
    "    # Extract font size of figure captions (Search for 'Figure' keyword)\n",
    "    caption_sizes = []\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line[\"spans\"]:\n",
    "                    if \"Figure\" in span[\"text\"]:  # Detect captions\n",
    "                        caption_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    #Find the most frequent figure caption font size\n",
    "    font_counts = Counter(caption_sizes)\n",
    "    figure_caption_font_size = font_counts.most_common(1)[0][0] if font_counts else None\n",
    "\n",
    "    return {\n",
    "        \"list_of_figures\": {\n",
    "            \"lof_present\": lof_present,\n",
    "            \"figure_caption_font_size\": figure_caption_font_size\n",
    "        }\n",
    "    }\n",
    "\n",
    "lof_info = extract_lof_info(\"toxicMeter.pdf\")\n",
    "print(lof_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abbreviations_section': {'abbreviations_section_present': False, 'abbreviations_sorted': 'N/A', 'abbreviations': {}}}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def extract_abbreviations_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_page = None\n",
    "    heading_font_size = None\n",
    "    abbreviations_dict = {}\n",
    "\n",
    "    # Step 1: Identify general heading font size from the first few pages\n",
    "    font_sizes = []\n",
    "    for page in doc[:5]:  # Check first 5 pages to identify common heading font\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue  # Skip blocks without text lines\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    font_sizes.append(round(span[\"size\"]))\n",
    "\n",
    "    # Determine most common heading font size\n",
    "    general_heading_font_size = max(font_sizes) if font_sizes else None\n",
    "\n",
    "    if general_heading_font_size is None:\n",
    "        return {\n",
    "            \"abbreviations_section\": {\n",
    "                \"abbreviations_section_present\": False,\n",
    "                \"abbreviations_sorted\": \"N/A\",\n",
    "                \"abbreviations\": {}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Step 2: Locate \"List of Abbreviations\" with the matched heading font size\n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if \"lines\" not in block:\n",
    "                continue\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    if span[\"size\"] == general_heading_font_size and (\n",
    "                        \"List of Abbreviations\" in span[\"text\"] or \"ABBREVIATIONS\" in span[\"text\"]\n",
    "                    ):\n",
    "                        abbreviations_page = page_num\n",
    "                        break\n",
    "            if abbreviations_page is not None:\n",
    "                break\n",
    "        if abbreviations_page is not None:\n",
    "            break\n",
    "\n",
    "    if abbreviations_page is None:\n",
    "        return {\n",
    "            \"abbreviations_section\": {\n",
    "                \"abbreviations_section_present\": False,\n",
    "                \"abbreviations_sorted\": \"N/A\",\n",
    "                \"abbreviations\": {}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Step 3: Extract abbreviations from the identified page\n",
    "    text = doc[abbreviations_page].get_text(\"dict\")\n",
    "    capture_abbreviations = False  # Start capturing only after heading\n",
    "\n",
    "    abbreviation_pattern = re.compile(r\"^([A-Z0-9\\-]+)[:\\s]+(.+)\")  # Match \"ABC: Definition\"\n",
    "\n",
    "    for block in text[\"blocks\"]:\n",
    "        if \"lines\" not in block:\n",
    "            continue  # Skip empty blocks\n",
    "        for line in block[\"lines\"]:\n",
    "            for span in line[\"spans\"]:\n",
    "                font_size = span[\"size\"]\n",
    "                content = span[\"text\"].strip()\n",
    "\n",
    "                # Step 4: Detect start of abbreviations section\n",
    "                if font_size == general_heading_font_size and (\"List of Abbreviations\" in content or \"ABBREVIATIONS\" in content):\n",
    "                    capture_abbreviations = True\n",
    "                    continue\n",
    "\n",
    "                # Step 5: Capture abbreviations only after the heading\n",
    "                if capture_abbreviations:\n",
    "                    match = abbreviation_pattern.match(content)\n",
    "                    if match:\n",
    "                        abbrev, definition = match.groups()\n",
    "                        abbreviations_dict[abbrev] = definition\n",
    "\n",
    "    # Step 6: Check if abbreviations are sorted\n",
    "    sorted_status = \"asc\" if list(abbreviations_dict.keys()) == sorted(abbreviations_dict.keys()) else \"unsorted\"\n",
    "\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": True,\n",
    "            \"abbreviations_sorted\": sorted_status,\n",
    "            \"abbreviations\": abbreviations_dict\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run the function\n",
    "abbr_info = extract_abbreviations_info(\"toxicMeter.pdf\")\n",
    "print(abbr_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "pdf_path = \"../dataset/pdfs/toxicMeter.pdf\" \n",
    "doc = fitz.open(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Content Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_of_contents\": {\n",
      "    \"toc_present\": true,\n",
      "    \"heading_font_size\": 16,\n",
      "    \"subheading_font_size\": 12\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def table_of_content_extractor(doc):\n",
    "    toc_text = \"\"\n",
    "    toc_found = False  # Flag to track if ToC has started\n",
    "    potential_toc = []  # Store potential ToC lines\n",
    "    toc_fonts = []  # Store font size information\n",
    "    toc_heading_size = None  # Track ToC heading font size (only once)\n",
    "    subheading_sizes = set()  # Track unique subheading font sizes\n",
    "\n",
    "    # Iterate through first few pages (ToC is usually at the beginning)\n",
    "    for page_num in range(min(10, len(doc))):  # Scan first 10 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect ToC heading (ensure we only capture the first occurrence)\n",
    "                        if re.search(r\"\\b(Table\\s*of\\s*Contents|Contents|Index)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not toc_found:  # Only set once\n",
    "                                toc_found = True  \n",
    "                                toc_heading_size = font_size  # Store only the first ToC heading font size\n",
    "                                toc_fonts.append((\"Heading\", line_text, font_size))\n",
    "                            toc_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If ToC has started, keep extracting until a matching font size is detected\n",
    "                        if toc_found:\n",
    "                            # Stop when encountering a section heading of the same size as the ToC heading\n",
    "                            if font_size == toc_heading_size:\n",
    "                                return {\n",
    "                                    \"table_of_contents\": {\n",
    "                                        \"toc_present\": True,\n",
    "                                        \"heading_font_size\": toc_heading_size,\n",
    "                                        \"subheading_font_size\": max(subheading_sizes) if subheading_sizes else None\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            # Identify ToC subheadings based on detected text patterns\n",
    "                            if re.match(r\"^\\d+(\\.\\d+)*\\s+[A-Za-z\\s]+\", line_text):  \n",
    "                                subheading_sizes.add(font_size)  # Store unique subheading font sizes\n",
    "                                toc_fonts.append((\"Subheading\", line_text, font_size))\n",
    "                            else:\n",
    "                                toc_fonts.append((\"Regular\", line_text, font_size))\n",
    "\n",
    "                            potential_toc.append(line_text)\n",
    "                            toc_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no ToC found, return False\n",
    "    return {\n",
    "        \"table_of_contents\": {\n",
    "            \"toc_present\": False,\n",
    "            \"heading_font_size\": None,\n",
    "            \"subheading_font_size\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "toc_data = table_of_content_extractor(doc)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(toc_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Figure Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"list_of_figures\": {\n",
      "    \"lof_present\": true,\n",
      "    \"figure_caption_font_size\": 12\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def list_of_figures_extractor(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    lof_text = \"\"\n",
    "    lof_found = False  # Flag to track if LoF has started\n",
    "    figure_caption_sizes = set()  # Store unique font sizes of figure captions\n",
    "    lof_heading_size = None  # Track LoF heading font size\n",
    "\n",
    "    # Iterate through first few pages (LoF is usually at the beginning)\n",
    "    for page_num in range(min(10, len(doc))):  # Scan first 10 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect LoF heading (ensuring we only capture the first occurrence)\n",
    "                        if re.search(r\"\\b(List\\s*of\\s*Figures|Figures|Figure Index)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not lof_found:  # Only set once\n",
    "                                lof_found = True  \n",
    "                                lof_heading_size = font_size  # Store LoF heading font size\n",
    "                            lof_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If LoF has started, keep extracting until a matching font size is detected\n",
    "                        if lof_found:\n",
    "                            # Identify figure captions (likely smaller font size than heading)\n",
    "                            if re.match(r\"^(Figure|Fig\\.|Table)\\s+\\d+[:.\\s]\", line_text):  \n",
    "                                figure_caption_sizes.add(font_size)  # Store caption font size\n",
    "\n",
    "                            # Stop when encountering a section heading of the same size as the LoF heading,\n",
    "                            # BUT only if we have already captured some figure captions.\n",
    "                            if font_size == lof_heading_size and figure_caption_sizes:\n",
    "                                return {\n",
    "                                    \"list_of_figures\": {\n",
    "                                        \"lof_present\": True,\n",
    "                                        \"figure_caption_font_size\": max(figure_caption_sizes)  # Return largest detected caption font\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            lof_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no LoF found, return False\n",
    "    return {\n",
    "        \"list_of_figures\": {\n",
    "            \"lof_present\": False,\n",
    "            \"figure_caption_font_size\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "lof_data = list_of_figures_extractor(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(lof_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviations Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"abbreviations_section\": {\n",
      "    \"abbreviations_section_present\": true,\n",
      "    \"abbreviations_sorted\": \"asc\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_abbreviations_section(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_text = \"\"\n",
    "    abbreviations_found = False  # Flag to track if abbreviations section has started\n",
    "    abbreviations = []  # Store extracted abbreviations\n",
    "    abbreviation_heading_size = None  # Store heading font size\n",
    "\n",
    "    # Iterate through first few pages (Abbreviations is usually at the beginning or middle)\n",
    "    for page_num in range(min(15, len(doc))):  # Scan first 15 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect Abbreviations heading\n",
    "                        if re.search(r\"\\b(Abbreviations|List of Abbreviations|Acronyms)\\b\", line_text, re.IGNORECASE):\n",
    "                            if not abbreviations_found:  # Capture only the first heading\n",
    "                                abbreviations_found = True  \n",
    "                                abbreviation_heading_size = font_size  # Store the font size of this section\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If Abbreviations section has started, keep extracting until a new section heading is found\n",
    "                        if abbreviations_found:\n",
    "                            # Stop when encountering a section heading of the same size as the Abbreviations heading\n",
    "                            if font_size == abbreviation_heading_size:\n",
    "                                return {\n",
    "                                    \"abbreviations_section\": {\n",
    "                                        \"abbreviations_section_present\": True,\n",
    "                                        \"abbreviations_sorted\": check_sorting_order(abbreviations)  # Determine sorting order\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "                            # Alternative method to extract abbreviations\n",
    "                            extracted_abbreviation = extract_abbreviation_from_line(line_text)\n",
    "                            print(extracted_abbreviation)\n",
    "                            if extracted_abbreviation:\n",
    "                                abbreviations.append(extracted_abbreviation)\n",
    "\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "\n",
    "    # If no abbreviations section found, return False\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": False,\n",
    "            \"abbreviations_sorted\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_abbreviation_from_line(line_text):\n",
    "    \"\"\"\n",
    "    Extract abbreviations using different patterns:\n",
    "    1. AI (Artificial Intelligence)\n",
    "    2. CNN: Convolutional Neural Network\n",
    "    3. NLP – Natural Language Processing\n",
    "    \"\"\"\n",
    "    print(line_text)\n",
    "    # Look for patterns like \"AI (Artificial Intelligence)\"\n",
    "    match_parentheses = re.match(r\"^([A-Z]{2,})\\s*\\((.+?)\\)$\", line_text)\n",
    "    if match_parentheses:\n",
    "        return match_parentheses.group(1)  # Extract \"AI\"\n",
    "\n",
    "    # Look for patterns like \"CNN: Convolutional Neural Network\"\n",
    "    match_colon = re.match(r\"^([A-Z]{2,})\\s*:\\s*(.+)$\", line_text)\n",
    "    if match_colon:\n",
    "        return match_colon.group(1)  # Extract \"CNN\"\n",
    "\n",
    "    # Look for patterns like \"NLP – Natural Language Processing\"\n",
    "    match_dash = re.match(r\"^([A-Z]{2,})\\s*[-–—]\\s*(.+)$\", line_text)\n",
    "    if match_dash:\n",
    "        return match_dash.group(1)  # Extract \"NLP\"\n",
    "\n",
    "    return None  # No match found\n",
    "\n",
    "def check_sorting_order(abbreviations):\n",
    "    \"\"\"Determine if abbreviations are sorted in ascending, descending, or no order.\"\"\"\n",
    "    if abbreviations == sorted(abbreviations):\n",
    "        return \"asc\"\n",
    "    elif abbreviations == sorted(abbreviations, reverse=True):\n",
    "        return \"desc\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "\n",
    "abbreviations_data = extract_abbreviations_section(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(abbreviations_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"abbreviations_section\": {\n",
      "    \"abbreviations_section_present\": false,\n",
      "    \"abbreviations_sorted\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_abbreviations_section(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    abbreviations_text = \"\"\n",
    "    abbreviations_found = False  # Flag to track if abbreviations section has started\n",
    "    abbreviations = []  # Store extracted abbreviations\n",
    "\n",
    "    # Iterate through the first few pages (Abbreviations section is usually in the early pages)\n",
    "    for page_num in range(min(15, len(doc))):  # Scan first 15 pages\n",
    "        text_blocks = doc[page_num].get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        font_size = round(span[\"size\"])  # Extract font size\n",
    "                        line_text = span[\"text\"].strip()\n",
    "\n",
    "                        # Detect Abbreviations heading\n",
    "                        if re.search(r\"\\b(Abbreviations|List of Abbreviations|Acronyms)\\b\", line_text, re.IGNORECASE):\n",
    "                            abbreviations_found = True  # Start collecting abbreviations\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "                            continue\n",
    "\n",
    "                        # If Abbreviations section has started, extract abbreviations\n",
    "                        if abbreviations_found:\n",
    "                            extracted_abbreviation = extract_abbreviation_from_line(line_text)\n",
    "                            if extracted_abbreviation:\n",
    "                                abbreviations.append(extracted_abbreviation)\n",
    "\n",
    "                            abbreviations_text += line_text + \"\\n\"\n",
    "\n",
    "                            # Detect potential new section heading (Stop extraction here)\n",
    "                            if is_new_section_heading(line_text):\n",
    "                                return {\n",
    "                                    \"abbreviations_section\": {\n",
    "                                        \"abbreviations_section_present\": True,\n",
    "                                        \"abbreviations_sorted\": check_sorting_order(abbreviations)  # Determine sorting order\n",
    "                                    }\n",
    "                                }\n",
    "\n",
    "    # If no abbreviations section found, return False\n",
    "    return {\n",
    "        \"abbreviations_section\": {\n",
    "            \"abbreviations_section_present\": False,\n",
    "            \"abbreviations_sorted\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_abbreviation_from_line(line_text):\n",
    "    \"\"\"\n",
    "    Extract abbreviations from a line by detecting:\n",
    "    1. AI - Artificial Intelligence\n",
    "    2. CNN : Convolutional Neural Network\n",
    "    3. NLP – Natural Language Processing\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^([A-Z0-9]{2,})\\s*[-–—:]\\s*(.+)$\", line_text)\n",
    "    if match:\n",
    "        return match.group(1)  # Extract only the short form (e.g., AI, CNN, NLP)\n",
    "\n",
    "    return None  # No abbreviation found\n",
    "\n",
    "def is_new_section_heading(line_text):\n",
    "    \"\"\"\n",
    "    Detect if a line is likely a new section heading:\n",
    "    - Fully capitalized words (e.g., \"INTRODUCTION\", \"METHODS\")\n",
    "    - Very short headings (1-3 words)\n",
    "    \"\"\"\n",
    "    if line_text.isupper() and len(line_text.split()) <= 5:\n",
    "        return True  # Likely a new section heading\n",
    "\n",
    "    return False  # Continue extracting abbreviations\n",
    "\n",
    "def check_sorting_order(abbreviations):\n",
    "    \"\"\"Determine if abbreviations are sorted in ascending, descending, or no order.\"\"\"\n",
    "    if abbreviations == sorted(abbreviations):\n",
    "        return \"asc\"\n",
    "    elif abbreviations == sorted(abbreviations, reverse=True):\n",
    "        return \"desc\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "# Example usage\n",
    "abbreviations_data = extract_abbreviations_section(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(abbreviations_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIGURE PLACEMENT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"figure_placement\": {\n",
      "    \"figure_caption_font_size\": 12,\n",
      "    \"figure_placement\": \"center\",\n",
      "    \"figure_caption_position\": \"above\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def figure_data_extractor(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_width = doc[0].rect.width  # Get the width of the first page for alignment checks\n",
    "\n",
    "    figure_placements = []  # Store placement data\n",
    "    caption_positions = []  # Store caption positions\n",
    "    caption_font_sizes = []  # Store caption font sizes\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        images = page.get_images(full=True)  # Extract all images (figures)\n",
    "\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]  # Get image reference\n",
    "            bbox = page.get_image_rects(xref)[0]  # Get bounding box of image (figure)\n",
    "\n",
    "            # Determine figure alignment\n",
    "            fig_x0, fig_y0, fig_x1, fig_y1 = bbox\n",
    "            fig_width = fig_x1 - fig_x0\n",
    "            page_center_x = page_width / 2\n",
    "\n",
    "            if abs((fig_x0 + fig_x1) / 2 - page_center_x) < fig_width * 0.1:\n",
    "                placement = \"center\"\n",
    "            elif fig_x0 < page_width * 0.3:\n",
    "                placement = \"left\"\n",
    "            else:\n",
    "                placement = \"right\"\n",
    "\n",
    "            # Find figure caption (text near the figure)\n",
    "            figure_caption, caption_font_size, caption_position = find_figure_caption(page, bbox)\n",
    "\n",
    "            if caption_font_size:\n",
    "                caption_font_sizes.append(caption_font_size)\n",
    "\n",
    "            if placement:\n",
    "                figure_placements.append(placement)\n",
    "\n",
    "            if caption_position:\n",
    "                caption_positions.append(caption_position)\n",
    "\n",
    "    # Determine most frequent values\n",
    "    most_common_placement = most_frequent(figure_placements)\n",
    "    most_common_caption_position = most_frequent(caption_positions)\n",
    "    most_common_caption_font_size = most_frequent(caption_font_sizes)\n",
    "\n",
    "    return {\n",
    "        \"figure_placement\": {\n",
    "            \"figure_caption_font_size\": most_common_caption_font_size,\n",
    "            \"figure_placement\": most_common_placement,\n",
    "            \"figure_caption_position\": most_common_caption_position\n",
    "        }\n",
    "    }\n",
    "\n",
    "def find_figure_caption(page, bbox):\n",
    "    \"\"\"\n",
    "    Find the caption text near the figure.\n",
    "    - If text appears *below* the figure, return \"below\"\n",
    "    - If text appears *above* the figure, return \"above\"\n",
    "    \"\"\"\n",
    "    fig_x0, fig_y0, fig_x1, fig_y1 = bbox\n",
    "    caption_text = None\n",
    "    caption_font_size = None\n",
    "    caption_position = None\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text_y0 = line[\"bbox\"][1]  # Get Y-position of text\n",
    "                    font_size = round(span[\"size\"])  # Extract font size\n",
    "                    line_text = span[\"text\"].strip()\n",
    "\n",
    "                    # Check if text is directly below the figure\n",
    "                    if fig_y1 < text_y0 < fig_y1 + font_size * 3:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"below\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "                    # Check if text is directly above the figure\n",
    "                    if fig_y0 - font_size * 3 < text_y0 < fig_y0:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"above\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "    return caption_text, caption_font_size, caption_position\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "figure_placement_data = figure_data_extractor(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(figure_placement_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TABLE PLACEMENT EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"table_placement\": {\n",
      "    \"table_caption_font_size\": 12,\n",
      "    \"table_placement\": \"right\",\n",
      "    \"table_caption_position\": \"above\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_table_placement(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_width = doc[0].rect.width  # Get the width of the first page for alignment checks\n",
    "\n",
    "    table_placements = []  # Store table alignment\n",
    "    caption_positions = []  # Store caption positions\n",
    "    caption_font_sizes = []  # Store caption font sizes\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        tables = find_tables(page)  # Find potential table bounding boxes\n",
    "\n",
    "        for table_bbox in tables:\n",
    "            # Determine table alignment\n",
    "            table_x0, table_y0, table_x1, table_y1 = table_bbox\n",
    "            table_width = table_x1 - table_x0\n",
    "            page_center_x = page_width / 2\n",
    "\n",
    "            if abs((table_x0 + table_x1) / 2 - page_center_x) < table_width * 0.1:\n",
    "                placement = \"center\"\n",
    "            elif table_x0 < page_width * 0.3:\n",
    "                placement = \"left\"\n",
    "            else:\n",
    "                placement = \"right\"\n",
    "\n",
    "            # Find table caption (text near the table)\n",
    "            table_caption, caption_font_size, caption_position = find_table_caption(page, table_bbox)\n",
    "\n",
    "            if caption_font_size:\n",
    "                caption_font_sizes.append(caption_font_size)\n",
    "\n",
    "            if placement:\n",
    "                table_placements.append(placement)\n",
    "\n",
    "            if caption_position:\n",
    "                caption_positions.append(caption_position)\n",
    "\n",
    "    # Determine most frequent values\n",
    "    most_common_placement = most_frequent(table_placements)\n",
    "    most_common_caption_position = most_frequent(caption_positions)\n",
    "    most_common_caption_font_size = most_frequent(caption_font_sizes)\n",
    "\n",
    "    return {\n",
    "        \"table_placement\": {\n",
    "            \"table_caption_font_size\": most_common_caption_font_size,\n",
    "            \"table_placement\": most_common_placement,\n",
    "            \"table_caption_position\": most_common_caption_position\n",
    "        }\n",
    "    }\n",
    "\n",
    "def find_tables(page):\n",
    "    \"\"\"\n",
    "    Identify potential tables by detecting large structured text blocks.\n",
    "    - Looks for multiple consecutive text lines forming a structured shape.\n",
    "    \"\"\"\n",
    "    table_bboxes = []\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block and len(block[\"lines\"]) > 2:  # More than 2 rows indicates a possible table\n",
    "            bbox = block[\"bbox\"]\n",
    "            table_bboxes.append(bbox)\n",
    "\n",
    "    return table_bboxes\n",
    "\n",
    "def find_table_caption(page, bbox):\n",
    "    \"\"\"\n",
    "    Find the caption text near the table.\n",
    "    - If text appears *below* the table, return \"below\"\n",
    "    - If text appears *above* the table, return \"above\"\n",
    "    \"\"\"\n",
    "    table_x0, table_y0, table_x1, table_y1 = bbox\n",
    "    caption_text = None\n",
    "    caption_font_size = None\n",
    "    caption_position = None\n",
    "\n",
    "    for block in page.get_text(\"dict\")[\"blocks\"]:\n",
    "        if \"lines\" in block:\n",
    "            for line in block[\"lines\"]:\n",
    "                for span in line[\"spans\"]:\n",
    "                    text_y0 = line[\"bbox\"][1]  # Get Y-position of text\n",
    "                    font_size = round(span[\"size\"])  # Extract font size\n",
    "                    line_text = span[\"text\"].strip()\n",
    "\n",
    "                    # Check if text is directly below the table\n",
    "                    if table_y1 < text_y0 < table_y1 + font_size * 3:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"below\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "                    # Check if text is directly above the table\n",
    "                    if table_y0 - font_size * 3 < text_y0 < table_y0:\n",
    "                        caption_text = line_text\n",
    "                        caption_font_size = font_size\n",
    "                        caption_position = \"above\"\n",
    "                        return caption_text, caption_font_size, caption_position\n",
    "\n",
    "    return caption_text, caption_font_size, caption_position\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "table_placement_data = extract_table_placement(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(table_placement_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT ALIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text_alignment\": {\n",
      "    \"text_alignment\": \"Justified\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def extract_text_alignment(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    alignment_counts = []  # Store detected alignments\n",
    "\n",
    "    for page_num in range(len(doc)):  # Loop through all pages\n",
    "        page = doc[page_num]\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "\n",
    "        for block in text_blocks:\n",
    "            if \"lines\" in block:\n",
    "                left_margins = []\n",
    "                right_margins = []\n",
    "\n",
    "                for line in block[\"lines\"]:\n",
    "                    x0, _, x1, _ = line[\"bbox\"]  # Get left & right positions of the line\n",
    "                    left_margins.append(x0)\n",
    "                    right_margins.append(x1)\n",
    "\n",
    "                # Compute alignment by analyzing variation in margins\n",
    "                left_variation = max(left_margins) - min(left_margins) if left_margins else 0\n",
    "                right_variation = max(right_margins) - min(right_margins) if right_margins else 0\n",
    "\n",
    "                if left_variation < 5 and right_variation < 5:\n",
    "                    alignment_counts.append(\"Justified\")\n",
    "                elif left_variation < 5:\n",
    "                    alignment_counts.append(\"Left\")\n",
    "                elif right_variation < 5:\n",
    "                    alignment_counts.append(\"Right\")\n",
    "                else:\n",
    "                    alignment_counts.append(\"Mixed\")\n",
    "\n",
    "    # Determine most frequent text alignment\n",
    "    most_common_alignment = most_frequent(alignment_counts)\n",
    "\n",
    "    return {\n",
    "        \"text_alignment\": {\n",
    "            \"text_alignment\": most_common_alignment\n",
    "        }\n",
    "    }\n",
    "\n",
    "def most_frequent(lst):\n",
    "    \"\"\"Find the most common element in a list\"\"\"\n",
    "    if not lst:\n",
    "        return None\n",
    "    return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "# Example usage\n",
    "text_alignment_data = extract_text_alignment(pdf_path)\n",
    "\n",
    "# Print the JSON output\n",
    "print(json.dumps(text_alignment_data, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
